### Chatbot using Flask & AWS Bedrock hosted Llama model

This is a simple web-based chatbot built using **Flask (Python)** as the backend and **Metaâ€™s LLaMA 3 model via AWS Bedrock** for generating AI responses. The frontend uses **HTML, CSS, and JavaScript** to deliver a clean and interactive experience.

---

### ğŸ”§ Technologies Used

- **Backend:** Python, Flask
- **Frontend:** HTML, CSS, JavaScript
- **AI Model:**  LLaMA 3 (8B) via AWS Bedrock
- **Others:** `boto3`, `dotenv` for API key management

---

### ğŸ“¸ Project Screenshot

![Chatbot UI](AWS_Bedrock_Lllama_Flask_Based_Chatbot.png)

---
### ğŸ“ Project Structure
```
Project:.
â”œâ”€â”€â”€static
â”‚ â”œâ”€â”€â”€css
â”‚ â”‚ â””â”€â”€â”€Chatbot_CSS.css
â”‚ â”œâ”€â”€â”€js
â”‚ â”‚ â””â”€â”€â”€script.js
â”‚ â””â”€â”€â”€chatbot_image.png
â”œâ”€â”€â”€templates
â”‚ â””â”€â”€â”€index.html
â”œâ”€â”€â”€app.py
â”œâ”€â”€â”€.env
â””â”€â”€â”€requirements.txt
```
---
### âš™ï¸ How It Works
- User inputs a message in the frontend.
- Flask receives the message and passes it to AWS Bedrockâ€™s `ConverseStream` API.
- Metaâ€™s LLaMA 3 generates a response based on a system prompt and user message.
- The AI response is returned and displayed on the frontend.
---
